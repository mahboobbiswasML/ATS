# ATS


ğŸ“„ README.txt â€” Run AI Resume Chat App Locally

âœ… Requirements

1. Python 3.10+ installed
2. VS Code
3. Ollama installed locally: https://ollama.com/download
4. Models:
   - llama2
   - nomic-embed-text

Install these models via terminal:
    ollama run llama2
    ollama pull nomic-embed-text

ğŸ“ Folder Structure

ai_resume_chat_pro/
â”‚
â”œâ”€â”€ app.py                   # Streamlit main app
â”œâ”€â”€ rag_pipeline.py          # RAG logic (vector store + chatbot)
â”œâ”€â”€ ranker.py                # Candidate scoring
â”œâ”€â”€ resume_parser.py         # Resume text extraction
â”œâ”€â”€ summarizer.py            # AI-generated summaries
â”œâ”€â”€ requirements.txt         # Dependencies
â””â”€â”€ README.txt               # This file

âš™ï¸ Setup Instructions

1. Clone/Unzip Project

If you downloaded a ZIP file, extract it in a folder:
    cd ai_resume_chat_pro

2. Create Virtual Environment
    python -m venv myenv
    source myenv/bin/activate     # On Windows: myenv\Scripts\activate

3. Install Dependencies
    pip install -r requirements.txt

4. Start Ollama Server
    ollama serve

Then load the required model:
    ollama run llama2

(Keep this terminal open)

5. Run the Streamlit App
    streamlit run app.py

Your browser should open at:
    http://localhost:8501

ğŸ’¡ Features

- Upload multiple resumes (PDF/DOCX)
- Analyze and rank candidates based on job description
- View candidate insights and scores
- Chat with an AI to explore resume details

â— Troubleshooting

- Embedding Error?
    Ensure nomic-embed-text is pulled:
        ollama pull nomic-embed-text

- Connection refused?
    Make sure you ran:
        ollama serve
